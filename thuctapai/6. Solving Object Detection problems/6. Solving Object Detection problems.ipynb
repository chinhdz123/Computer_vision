{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f68db2b1",
   "metadata": {},
   "source": [
    "<h3>1. Object detection là gì?<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0836cc4",
   "metadata": {},
   "source": [
    "Sẽ khá khó cho người mới bắt đầu để phân biệt các nhiệm vụ khác nhau của computer vision. Chẳng hạn như phân loại hình ảnh (image classification) là gì? Định vị vật thể (object localization) là gì? Sự khác biệt giữa định vị vật thể (object localization) và phát hiện đối tượng (object detection) là gì? Đây là những khái niệm có thể gây nhầm lẫn, đặc biệt là khi cả ba nhiệm vụ đều liên quan đến nhau. Hiều một cách đơn giản:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125df987",
   "metadata": {},
   "source": [
    "   * Phân loại hình ảnh (image classification): liên quan đến việc gán nhãn cho hình ảnh.\n",
    "   * Định vị vật thể (object localization): liên quan đến việc vẽ một hộp giới hạn (bounding box) xung quanh một hoặc nhiều đối tượng trong hình ảnh nhằm khoanh vùng đối tượng.\n",
    "   *Phát hiện đối tượng (object detection): Là nhiệm vụ khó khăn hơn và là sự kết hợp của cả hai nhiệm vụ trên: Vẽ một bounding box xung quanh từng đối tượng quan tâm trong ảnh và gán cho chúng một nhãn. Kết hợp cùng nhau, tất cả các vấn đề này được gọi là object recognition hoặc object detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564ea687",
   "metadata": {},
   "source": [
    "Bài viết này sẽ giới thiệu một cách khái quát các vấn đề của object detection và các mô hình deep learning state-of-art được thiết kế để giải quyết nó."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdee5f86",
   "metadata": {},
   "source": [
    "<h3>2. Như thế nào là nhận dạng đối tượng?<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba53243",
   "metadata": {},
   "source": [
    "Nhận dạng đối tượng là một thuật ngữ chung để mô tả một tập hợp các nhiệm vụ thị giác máy tính có liên quan liên quan đến việc xác định các đối tượng trong ảnh kỹ thuật số.\n",
    "\n",
    "Phân loại hình ảnh liên quan đến việc dự đoán lớp của một đối tượng trong một hình ảnh. Định vị vật thể đề cập đến việc xác định vị trí của một hoặc nhiều đối tượng trong một hình ảnh và vẽ bounding box xung quanh chúng. Phát hiện đối tượng kết hợp hai nhiệm vụ trên và thực hiện cho một hoặc nhiều đối tượng trong hình ảnh. Chúng ta có thể phân biệt giữa ba nhiệm vụ thị giác máy tính cơ bản trên thông qua input và output của chúng như sau:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c012d3d9",
   "metadata": {},
   "source": [
    "Một số định nghĩa khác cũng rất quan trọng trong computer vision là phân đoạn đối tượng (object segmentation), trong đó các đối tượng được nhận dạng bằng cách làm nổi bật các pixel cụ thể của đối tượng thay vì bounding box. Và image captioning kết hợp giữa các kiến trúc mạng CNN và LSTM để đưa ra các lý giải về hành động hoặc nội dung của một bức ảnh."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff64f37",
   "metadata": {},
   "source": [
    "Bên dưới là sơ đồ tổng hợp các tác vụ của computer vision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf47d2f",
   "metadata": {},
   "source": [
    "![nv](nv.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a2d5b6",
   "metadata": {},
   "source": [
    "Điểm khác biệt nữa trong các mô hình image classification so với Object Recognition đó là mô hình image classification có hàm loss function chỉ dựa trên sai số giữa nhãn dự báo và nhãn thực tế trong khi object detection đánh giá dựa trên sai số giữa nhãn dự báo và sai số khung hình dự báo so với thực tế."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3d16e4",
   "metadata": {},
   "source": [
    "<h3>3. Các thuật ngữ sử dụng trong bài<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfcac5c",
   "metadata": {},
   "source": [
    "   * region proposal: Vùng đề xuất, là những vùng mà có khả năng chứa đối tượng hoặc hình ảnh ở bên trong nó.\n",
    "   * bounding box: Là hình chữ nhật được vẽ bao quan đối tượng nhằm xác định đối tượng.\n",
    "   * offsets: Là các tham số giúp xác định bounding box bao gồm tâm của bounding box  và chiều dài, chiều rộng .\n",
    "   * anchor box: Chính là một bounding box cơ sở để xác định bounding box bao quanh vật thể dựa trên các phép dịch tâm và scale kích thước chiều dài, rộng. Mỗi loại anchor box sẽ phù hợp để tìm ra bounding box cho 1 loại vật thể đặc trưng. Chẳng hạn vật thể là con người thường có chiều cao > chiều rộng trong khi đoàn tàu sẽ có chiều rộng lớn hơn nhiều lần chiều cao.\n",
    "   * feature: Các đặc trưng được tạo ra từ một mạng deep CNN chẳng hạn Alexnet hoặc VGG16 giúp nhận diện nhãn của hình ảnh.\n",
    "   * pipeline: Là một tợp hợp các bước xử lý liên tiếp nhận đầu vào là dữ liệu (ảnh, âm thanh, các trường dữ liệu) và trả ra kết quả dự báo ở output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c3bd0d",
   "metadata": {},
   "source": [
    "<h3>4. Lớp các mô hình họ R-CNN<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1c27a5",
   "metadata": {},
   "source": [
    "R-CNN (regions with CNN features) là lớp các mô hình xác định vùng đặc trưng dựa trên các mạng CNN được phát triển bởi Ross Girshick và các cộng sự. Lớp các mô hình này gồm 3 mô hình chính là R-CNN, Fast R-CNN và Faster-RCNN được thiết kế cho các nhiệm vụ định vị vật thể và nhận diện vật thể."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0f817c",
   "metadata": {},
   "source": [
    "___4.1. R-CNN (2014)___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e5b96d",
   "metadata": {},
   "source": [
    "R-CNN được giới thiệu lần đầu vào 2014 bởi Ross Girshick và các cộng sự ở UC Berkeley một trong những trung tâm nghiên cứu AI hàng đầu thế giới trong bài báo Rich feature hierarchies for accurate object detection and semantic segmentation.\n",
    "\n",
    "Nó có thể là một trong những ứng dụng nền móng đầu tiên của mạng nơ ron tích chập đối với vấn đề định vị, phát hiện và phân đoạn đối tượng. Cách tiếp cận đã được chứng minh trên các bộ dữ liệu điểm chuẩn, đạt được kết quả tốt nhất trên bộ dữ liệu VOC-2012 và bộ dữ liệu phát hiện đối tượng ILSVRC-2013 gồm 200 lớp.\n",
    "\n",
    "Kiến trúc của R-CNN gồm 3 thành phần đó là:\n",
    "\n",
    "Vùng đề xuất hình ảnh (Region proposal): Có tác dụng tạo và trích xuất các vùng đề xuất chứa vật thể được bao bởi các bounding box.\n",
    "\n",
    "Trích lọc đặc trưng (Feature Extractor): Trích xuất các đặc trưng giúp nhận diện hình ảnh từ các region proposal thông qua các mạng deep convolutional neural network.\n",
    "\n",
    "Phân loại (classifier): Dựa vào input là các features ở phần trước để phân loại hình ảnh chứa trong region proposal về đúng nhãn.\n",
    "\n",
    "Kiến trúc của mô hình được mô tả trong biểu đồ bên dưới:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c04495",
   "metadata": {},
   "source": [
    "![rcnn](r-cnn.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6719c8cd",
   "metadata": {},
   "source": [
    "Sơ đồ pipeline xử lý trong mô hình mạng R-CNN. Ta có thể nhận thấy các hình ảnh con được trích xuất tại bước 2 với số lượng rất lớn (khoảng 2000 region proposals). Tiếp theo đó áp dụng một mạng deep CNN để tính toán các feature tại bước 3 và trả ra kết quả dự báo nhãn ở bước 4 như một tác vụ image classification thông thường."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a7774f",
   "metadata": {},
   "source": [
    "Một kỹ thuật được sử dụng để đề xuất các region proposal hoặc các bounding box chứa các đối tượng tiềm năng trong hình ảnh được gọi là “selective search”, các region proposal có thể được phát hiện bởi đa dạng những thuật toán khác nhau. Nhưng điểm chung là đều dựa trên tỷ lệ IoU giữa bounding box và ground truth box.\n",
    "\n",
    "Đây là một ứng dụng tương đối đơn giản và dễ hiểu của CNN đối với vấn đề object localization và object detection. Một nhược điểm của phương pháp này là chậm, đòi hỏi phải vượt qua nhiều module độc lập trong đó có trích xuất đặc trưng từ một mạng CNN học sâu trên từng region proposal được tạo bởi thuật toán đề xuất vùng chứa ảnh. Đây là một vấn đề chính cần giải quyết vì bài viết mô tả mô hình hoạt động trên khoảng 2000 vùng được đề xuất cho mỗi hình ảnh tại thời điểm thử nghiệm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f708ba72",
   "metadata": {},
   "source": [
    "___4.2. Fast R-CNN (2015)___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45a8ead",
   "metadata": {},
   "source": [
    "Dựa trên thành công của R-CNN, Ross Girshick (lúc này đã chuyển sang Microsoft Research) đề xuất một mở rộng để giải quyết vấn đề của R-CNN trong một bài báo vào năm 2015 với tiêu đề rất ngắn gọn Fast R-CNN.\n",
    "\n",
    "Bài báo chỉ ra những hạn chế của R-CNN đó là:\n",
    "\n",
    "   * Training qua một pipeline gồm nhiều bước: Pipeline liên quan đến việc chuẩn bị và vận hành ba mô hình riêng biệt.\n",
    "   * Chi phí training tốn kém về số lượng bounding box và thời gian huấn luyện: Mô hình huấn luyện một mạng CNN học sâu trên rất nhiều region proposal cho mỗi hình ảnh nên rất chậm.\n",
    "   * Phát hiện đối tượng chậm: Tốc độ xử lý không thể đảm bảo realtime.\n",
    "Trước đó một bài báo đã đề xuất phương pháp để tăng tốc kỹ thuật được gọi là mạng tổng hợp kim tự tháp - Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition, hoặc SPPnets vào năm 2014. Phương pháp này đã tăng tốc độ trích xuất features nhờ lan truyền thuận trên bộ nhớ đệm.\n",
    "\n",
    "Điểm đột phá của Fast R-CNN là sử dụng một single model thay vì pipeline để phát hiện region và classification cùng lúc.\n",
    "\n",
    "Kiến trúc của mô hình trích xuất từ bức ảnh một tập hợp các region proposals làm đầu vào được truyền qua mạng deep CNN. Một pretrained-CNN, chẳng hạn VGG-16, được sử dụng để trích lọc features. Phần cuối của deep-CNN là một custom layer được gọi là layer vùng quan tâm (Region of Interest Pooling - RoI Pooling) có tác dụng trích xuất các features cho một vùng ảnh input nhất định.\n",
    "\n",
    "Sau đó các features được kết bởi một lớp fully connected. Cuối cùng mô hình chia thành hai đầu ra, một đầu ra cho dự đoán nhãn thông qua một softmax layer và một đầu ra khác dự đoán bounding box (kí hiệu là bbox) dựa trên hồi qui tuyến tính. Quá trình này sau đó được lặp lại nhiều lần cho mỗi vùng RoI trong một hình ảnh.\n",
    "\n",
    "Kiến trúc của mô hình được tóm tắt trong hình dưới đây, được lấy từ bài báo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9ab342",
   "metadata": {},
   "source": [
    "![fast-r-cnn](fast-r-cnn.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ddac2e",
   "metadata": {},
   "source": [
    "Mô hình này nhanh hơn đáng kể cả về huấn luyện và dự đoán, tuy nhiên vẫn cần một tập hợp các region proposal được đề xuất cùng với mỗi hình ảnh đầu vào."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837e6e4e",
   "metadata": {},
   "source": [
    "___4.3. Faster R-CNN (2016)___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897c0003",
   "metadata": {},
   "source": [
    "![faster](faster.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b6ba49",
   "metadata": {},
   "source": [
    "Ở giai đoạn sớm sử dụng một mạng deep CNN để tạo ra một feature map. Khác với Fast R-CNN, kiến trúc này không tạo RoI ngay trên feature map mà sử dụng feature map làm đầu vào để xác định các region proposal thông qua một RPN network. Đồng thời feature maps cũng là đầu vào cho classifier nhằm phân loại các vật thể của region proposal xác định được từ RPN network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c150e0",
   "metadata": {},
   "source": [
    "RPN hoạt động bằng cách lấy đầu ra của một mạng pretrained deep CNN, chẳng hạn như VGG-16, và truyền feature map vào một mạng nhỏ và đưa ra nhiều region proposals và nhãn dự đoán cho chúng. Region proposals là các bounding boxes, dựa trên các anchor boxes hoặc hình dạng được xác định trước được thiết kế để tăng tốc và cải thiện khả năng đề xuất vùng. Dự đoán của nhãn được thể hiện dưới dạng nhị phân cho biết region proposal có xuất hiện vật thể hoặc không.\n",
    "\n",
    "Một quy trình huấn luyện xen kẽ được sử dụng trong đó cả hai mạng con được đào tạo cùng một lúc. Điều này cho phép các tham số trong feature dectector của deep CNN được tinh chỉnh cho cả hai tác vụ cùng một lúc.\n",
    "\n",
    "Tại thời điểm viết, kiến trúc Faster R-CNN này là đỉnh cao của họ model R-CNN và tiếp tục đạt được kết quả gần như tốt nhất trong các nhiệm vụ nhận diện đối tượng. Một mô hình mở rộng hỗ trợ cho phân đoạn hình ảnh, được mô tả trong bài báo năm 2017 có tựa đề Mask R-CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ecfa3f",
   "metadata": {},
   "source": [
    "<h3>5. Lớp các mô hình họ YOLO<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f5e1d9",
   "metadata": {},
   "source": [
    "Một họ mô hình nhận dạng đối tượng phổ biến khác được gọi chung là YOLO. YOLO không phải là bạn chỉ sống một lần đâu nhé, nó có nghĩa là bạn chỉ nhìn một lần (you only look one), được phát triển bởi Joseph Redmon, và các cộng sự.\n",
    "\n",
    "Các mô hình R-CNN nói chung có thể chính xác hơn, tuy nhiên họ mô hình YOLO nhanh hơn rất rất nhiều so với R-CNN, và thậm chí đạt được việc phát hiện đối tượng trong thời gian thực."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b91769",
   "metadata": {},
   "source": [
    "___5.1. YOLO (2015)___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c133ed1d",
   "metadata": {},
   "source": [
    "Phương pháp chính dựa trên một mạng neural network duy nhất được huấn luyện dạng end-to-end model. Mô hình lấy input là một bức ảnh và dự đoán các bounding box và nhãn lớp cho mỗi bounding box. Do không sử dụng region proposal nên kỹ thuật này có độ chính xác thấp hơn (ví dụ: nhiều lỗi định vị vật thể - localization error hơn), mặc dù hoạt động ở tốc độ 45 fps (khung hình / giây) và tối đa 155 fps cho phiên bản tối ưu hóa tốc độ. Tốc độ này còn nhanh hơn cả tốc độ khung hình của máy quay phim thông thường chỉ vào khoảng 24 fps.\n",
    "\n",
    "Mô hình hoạt động bằng cách trước tiên phân chia hình ảnh đầu vào thành một lưới các ô (grid of cells), trong đó mỗi ô chịu trách nhiệm dự đoán các bounding boxes nếu tâm của nó nằm trong ô. Mỗi grid cell (tức 1 ô bất kì nằm trong lưới ô) dự đoán các bounding boxes được xác định dựa trên tọa độ x, y (thông thường là tọa độ tâm, một số phiên bản là tọa độ góc trên cùng bên trái) và chiều rộng (width) và chiều cao (height) và độ tin cậy (confidence) về khả năng chứa vật thể bên trong. Ngoài ra các dự đoán nhãn cũng được thực hiện trên mỗi một bonding box.\n",
    "\n",
    "Ví dụ: một hình ảnh có thể được chia thành lưới 7 × 7 và mỗi ô trong lưới có thể dự đoán 2 bounding box, kết quả trả về 98 bounding box được đề xuất. Sau đó, một sơ đồ xác suất nhãn (gọi là class probability map) với các confidence được kết hợp thành một tợp hợp bounding box cuối cùng và các nhãn. Hình ảnh được lấy từ bài báo dưới đây tóm tắt hai kết quả đầu ra của mô hình."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00413b72",
   "metadata": {},
   "source": [
    "![NE4Xbie](NE4Xbie.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e625e658",
   "metadata": {},
   "source": [
    "___5.2. YOLOv2 (2016) và YOLOv3 (2018)___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2758df8",
   "metadata": {},
   "source": [
    "Mặc dù biến thể của YOLO được gọi là YOLOv2, một instance của mô hình theo như mô tả đã được đào tạo trên hai bộ dữ liệu nhận dạng đối tượng, và có khả năng dự đoán lên tới 9000 loại đối tượng khác nhau, do đó được đặt tên là YOLO9000. Với con số này thì mô hình này đã tiến xa hơn rất nhiều so với mọi mô hình trước đó về số lượng các loại đối tượng có khả năng phát hiện.\n",
    "\n",
    "Một số thay đổi về huấn luyện và kiến trúc đã được thực hiện, chẳng hạn như việc sử dụng batch normalization cho hàng loạt và hình ảnh đầu vào phân giải cao.\n",
    "\n",
    "Giống như Faster R-CNN, mô hình YOLOv2 sử dụng anchor boxes, bounding box được xác định trước với hình dạng và kích thước hợp lý được tùy chỉnh trong quá trình huấn luyện. Sự lựa chọn các bounding boxes cho hình ảnh được xử lý trước bằng cách sử dụng thuật toán phân cụm k-mean trên tập dữ liệu huấn luyện.\n",
    "\n",
    "Điều quan trọng, các predicted bounding box được tinh chỉnh để cho phép các thay đổi nhỏ có tác động ít hơn đến các dự đoán, dẫn đến mô hình ổn định hơn. Thay vì dự đoán trực tiếp vị trí và kích thước, các offsets (tức tọa độ tâm, chiều dài và chiều rộng) được dự đoán để di chuyển và định hình lại các pre-defined anchor boxes tại mỗi một grid cell thông qua hàm logistic.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
